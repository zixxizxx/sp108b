## 第五章--锁定。

大多数内核(包括xv6)交错执行多个活动。交错的一个来源是多处理器硬件：具有多个CPU独立执行的计算机，例如xv6的RISC-V。这些多个CPU共享物理RAM，xv6利用这种共享来维护所有CPU读写的数据结构。这种共享增加了一个CPU读取数据结构而另一个CPU中途更新数据结构的可能性，甚至增加了多个CPU同时更新相同数据的可能性；如果不仔细设计，这种并行访问很可能会产生不正确的结果或损坏的数据结构。即使在单处理器上，内核也可能在多个线程之间切换CPU，导致它们的执行交错。最后，如果中断发生在错误的时间，则修改与某些可中断代码相同的数据的设备中断处理程序可能会损坏数据。单词‘并发’是指由于多处理器并行性、线程切换或中断而使多个指令流交错的情况。

内核充满了并发访问的数据。例如，两个CPU可以同时调用‘kalloc`，从而同时从空闲列表的头部弹出。内核设计者喜欢考虑大量的并发性，因为它可以通过并行性提高性能和提高响应性。然而，尽管存在这样的并发性，内核设计者还是花费了大量的精力来说服自己的正确性。有很多方法可以得出正确的代码，其中一些比另一些更容易推理。以并发下的正确性为目标的策略，以及支持这些策略的抽象，被称为“并发控制”技术。Xv6使用许多并发控制技术，具体取决于具体情况；还可以使用更多技术。本章重点介绍一种广泛使用的技术：锁。

锁提供互斥，确保一次只有一个CPU可以持有锁。

如果程序员将锁与每个共享数据项相关联，并且代码在使用项时始终持有关联的锁，则该项一次将仅由一个CPU使用。在这种情况下，我们说锁保护数据项。

本章的其余部分解释为什么xv6需要锁，xv6如何实现它们，以及它如何使用它们。

![图5.1：示例RACE](../img/Fig5.1.png)

### 5.1竞争条件。

作为我们为什么需要锁的一个例子，考虑一个可从多处理器上的任何CPU访问的链表。列表支持推送和弹出操作，可以并发调用。Xv6的内存分配器以这种方式工作；kalloc()(kernel/kalloc.c：69)从空闲页面列表中弹出一页内存，而kfree()(kernel/kalloc.c：47)将页面推送到空闲列表。

如果没有并发请求，您可以按如下方式实现list push操作：

```c
1  struct element {
2    int data;
3    struct element *next;
4  };
5
6  struct element *list = 0;
7
8  void
9  push(int data)
10 {
11   struct element *l;
12
13   l = malloc(sizeof *l);
14   l->data = data;
15   l->next = list;
16   list = l;
17 }
```

如果隔离执行，则此实现是正确的。但是，如果并发执行多个副本，则代码不正确。如果两个CPU同时执行推送，则两个CPU都可能先执行第15行，然后再执行第16行(参见图5.1)。然后将有两个列表元素，其Next值设置为先前的值Oflist。当第16行的两个赋值为olisthapping时，第二个赋值将覆盖第一个赋值；第一个赋值中涉及的元素将丢失。

第16行的丢失更新是“竞争条件”的一个例子。争用条件是同时访问存储器位置，并且至少一个访问是写入的情况。争用通常是bug的征兆，要么是更新丢失(如果访问是写入)，要么是对未完全更新的数据结构的读取。竞争的结果取决于所涉及的两个CPU的确切时间，以及内存系统如何对它们的内存操作进行排序，这可能会使竞争引起的错误难以重现和调试。例如，在调试推送时添加打印语句可能会更改执行的时间，从而使竞争消失。

避免比赛的通常方法是使用锁。锁确保了‘互斥’，因此一次只有一个CPU可以执行敏感的推流线路；这使得上面的场景不可能出现。

上述代码的正确锁定版本只添加了几行(以黄色突出显示)：


```c
6 struct element *list = 0;
7 struct lock listlock;
8
9 void
10 push(int data)
11 {
12   struct element *l;
13   l = malloc(sizeof *l);
14   l->data = data;
15
16   acquire(&listlock);
17   l->next = list;
18   list = l;
19   release(&listlock);
20 }
```

在`quire`和`release ase`之间的指令序列通常被称为‘临界区’。该锁通常被称为保护列表。

当我们说锁保护数据时，我们实际上是指锁保护应用于数据的某些不变量集合。不变量是跨操作维护的数据结构的属性。通常，操作的正确行为取决于操作开始时不变量是否为真。该操作可能会暂时违反不变量，但必须在完成之前重新建立它们。例如，在链表的情况下，不变量是list指向列表中的第一个元素，并且每个元素的snextfield指向下一个元素。Push的实现暂时违反了这个不变量：在第17行，l指向下一个列表元素，但是List还没有指向它(在第18行重新建立)。我们上面检查的争用情况的发生是因为第二个CPU在列表不变量(临时)被违反时执行依赖于列表不变量的代码。正确使用锁可以确保一次只有一个CPU可以对临界区中的数据结构进行操作，这样当数据结构的不变量不成立时，没有CPU会执行数据结构操作。

您可以将锁视为“序列化”并发临界区，以便它们一次运行一个，从而保留不变量(假设临界区在隔离中是正确的)。您还可以认为由同一锁保护的临界区彼此之间是原子的，因此每个临界区只能看到来自较早临界区的完整更改集，而不会看到部分完成的更新。如果多个进程同时想要同一个锁，或者说该锁经历了`争用`，我们就说它们是`冲突的‘。

请注意，将`quire`提前入推是正确的。例如，将对`quire`的调用移到第13行之前就可以了。这可能会降低并行性，因为这样对`malloc`的调用也会被序列化。下面的使用锁一节提供了一些关于在哪里插入`quire`和`release ase`调用的指导。

### 5.2代码：锁定。

Xv6有两种锁：旋转锁和休眠锁。我们先从旋转锁开始。Xv6将一个自旋锁表示为一个`struct自旋锁`(kernel/splock.h：2)。结构中的重要字段是锁定的，该字在锁可用时为零，持有时为非零值。从逻辑上讲，xv6应该通过执行如下代码“获取”锁


```c
21 void
22 acquire(struct spinlock *lk) // does not work!
23 {
24   for(;;) {
25     if(lk->locked == 0) {
26       lk->locked = 1;
27       break;
28     }
29   }
30 }
```

不幸的是，此实现不能保证多处理器上的互斥。可能会发生这样的情况：两个CPU同时到达第25行，看到`lk->locked`为零，然后两个CPU都通过执行第26行来获取锁。此时，两个不同的CPU持有锁，这违反了互斥属性。我们需要的是一种方法，使第25行和第26行作为“原子”(即，不可分割)步骤执行。

因为锁被广泛使用，所以多核处理器通常提供实现第25和26行的原子版本的指令。在RISC-V上，此指令是amoswap r，A。amosw读取内存地址sa处的值，将registerr的内容写入该地址，并将其读取的值放入intor。也就是说，它交换寄存器的内容和内存地址。它使用特殊硬件自动执行此序列，以防止任何其他CPU使用读取和写入之间的内存地址。

Xv6的`quire`(kernel/splock.c：22)使用可移植的C库调用__sync_lock_test_and_set，归结起来就是amoswap指令；返回值是`lk->locked`的旧(交换)内容。`quire`函数在循环中包装交换，重试(旋转)，直到它获得锁为止。每次迭代将1换成`lk->locked`并检查之前的值；如果之前的值是0，则我们已经获得了锁，并且交换将`lk->locked`设置为1。如果前面的值是1，那么其他CPU持有锁，并且我们将其中一个自动交换为`lk->locked`这一事实并没有改变它的值。

一旦获得锁，‘quire`记录获得锁的CPU以进行调试。

`lk->cpu`字段受锁保护，只能在持有锁时更改。

函数`release ase`(kernel/splock.c：46)与`quiqure`相反：它会清除`lk->cpu`字段，然后释放锁。从概念上讲，此次发布只需要给`lk->locked`赋零即可。

C标准允许编译器实现具有多个存储指令的赋值，因此C赋值相对于并发代码可能是非原子的。相反，`release ase`使用执行原子赋值的C库函数__SYNC_LOCK_RELEASE。此函数还可归结为RISC-Vamoswap指令。

### 5.3代码：使用锁。

Xv6在许多地方使用锁以避免争用条件。要查看与上面非常相似的简单示例，请查看`kalloc`(kernel/kalloc.c:69)andfree(kernel/kalloc.c:34).。尝试练习1和2，看看如果这些函数省略锁会发生什么情况。您可能会发现很难触发不正确的行为，这表明很难可靠地测试代码是否没有锁定错误和竞争。xv6也有一些比赛，这并不是不可能的。

使用锁的一个困难部分是决定使用多少锁，以及每个锁应该保护哪些数据和不变量。这里有几个基本原则。首先，只要一个CPU可以在另一个CPU可以读写变量的同时写入变量，就应该使用锁来防止这两个操作重叠。其次，记住锁保护不变量：如果一个不变量涉及多个内存位置，通常需要用一个锁来保护所有这些位置，以确保维护不变量。

上面的规则说明了何时需要锁，但没有说明何时不需要锁，而且为了提高效率，重要的是不要锁得太多，因为锁会降低并行性。

如果并行性不重要，那么可以安排只有一个线程，而不用担心锁。一个简单的内核可以在多处理器上做到这一点，方法是拥有单个锁，该锁必须在进入内核时获取，并在退出内核时释放(尽管管道读取或‘wait`等系统调用会带来问题)。许多单处理器操作系统已经转换为使用这种方法在多处理器上运行，有时称为“大内核锁”，但这种方法牺牲了并行性：一次只能有一个CPU在内核中执行。如果内核执行任何繁重的计算，使用更大的一组更细粒度的锁会更有效，这样内核就可以在多个CPU上同时执行。

作为粗粒度锁定的一个示例，xv6的‘kalloc`.callocator有一个受单个锁保护的空闲列表。如果不同CPU上的多个进程试图同时分配页面，则每个进程都必须通过旋转`quire`来等待轮到它。旋转会降低性能，因为这不是有用的工作。如果争用锁浪费了很大一部分CPU时间，也许可以通过更改分配器的设计来提高性能，使其具有多个空闲列表，每个列表都有自己的锁，以允许真正的并行分配。
作为细粒度锁定的一个示例，xv6对每个文件都有单独的锁，因此操作不同文件的进程通常无需等待对方的锁就可以继续进行。如果希望允许进程同时写入同一文件的不同区域，则可以使文件锁定方案更加细粒度。最终，锁定粒度决策需要由性能度量和复杂性考虑因素驱动。

在接下来的章节解释xv6的每个部分时，他们将提到xv6使用锁来处理并发的示例。作为预览，图5.2列出了xv6中的所有锁。


Lock           | Description
---------------|-----------------------------------------
bcache.lock    | Protects allocation of block buffer cache entries
cons.lock      | Serializes access to console hardware, avoids intermixed output
ftable.lock    | Serializes allocation of a  `struct file`  in file table
icache.lock    | Protects allocation of inode cache entries
vdisk_lock     | Serializes access to disk hardware and queue of DMA descriptors
kmem.lock      | Serializes allocation of memory
log.lock       | Serializes operations on the transaction log pipe’s pi->lock Serializes operations on each pipe
pid_lock       | Serializes increments of next_pid proc’s `p->lock` Serializes changes to process’s state tickslock Serializes operations on the ticks counter
inode’s `ip->lock` | Serializes operations on each inode and its content
buf’s `b->lock`  | Serializes operations on each block buffer

> Figure 5.2: Locks in xv6

### 5.4死锁和锁顺序。

如果通过内核的代码路径必须同时持有多个锁，则所有代码路径必须以相同的顺序获取这些锁，这一点很重要。如果他们不这样做，就有“僵局”的风险。假设xv6中的两个代码路径需要锁A和B，但是代码路径1按照A-B的顺序获取锁，另一个路径按照B-A的顺序获取它们，假设线程T1执行代码路径1并获取锁A，线程T2执行代码路径2并获取锁B。接下来，T1将尝试获取锁B，T2将尝试获取锁A。这两个获取都将无限期阻塞，因为在这两种情况下，另一个线程都持有所需的锁，并且在获取返回之前不会释放它。若要避免此类死锁，所有代码路径必须以相同的顺序获取锁。需要全局锁获取顺序意味着锁实际上是每个函数规范的一部分：调用者调用函数的方式必须导致按照商定的顺序获取锁。

由于“sleep`”的工作方式，Xv6有许多长度为2的锁顺序链，涉及每个进程的锁(每个“struct process”中的锁)(请参见第6章)。例如，consoleintr(kernel/console.c：143)是处理键入字符的中断例程。当换行符到达时，任何等待控制台输入的进程都应该被唤醒。为此，consoleintr在调用`wakeup`时保持holdscons.lock，该函数获取等待进程的锁以将其唤醒。因此，全局死锁避免锁定顺序包括这样一条规则，即必须在任何进程锁之前获取con.lock。文件系统代码包含xv6最长的锁链。

例如，创建文件需要同时持有对目录的锁定、对新文件的inode的锁定、对磁盘块缓冲区的锁定、磁盘驱动程序的vdisk_lock和调用进程的`p->lock`。为了避免死锁，文件系统代码始终按照上一句话中提到的顺序获取锁。

遵守全球避免僵局的命令可能会出人意料地困难。有时锁定顺序与逻辑程序结构冲突，例如，可能代码模块M1调用模块M2，但是锁定顺序要求在M1中的锁定之前获取M2中的锁定。有时锁的标识是事先不知道的，可能是因为必须持有一个锁才能发现下一个要获取的锁的标识。在文件系统中查找路径名中的连续组件时，以及在‘wait`和’exit`的代码中查找进程表查找子进程时，都会出现这种情况。最后，死锁的危险通常会限制人们如何进行细粒度的锁定方案，因为更多的锁通常意味着更多的死锁机会。避免死锁的需要通常是内核实现中的一个主要因素。

### 5.5锁和中断处理程序。

某些xv6自旋锁保护线程和中断处理程序都使用的数据。例如，lockintrTimer中断处理程序可能会在内核线程读取`sys_sleep`(kernel/sysproc.c：64)中的`ticks`(kernel/trap.c：163)的同时增加`ticks`(kernel/trap.c：163)。锁`tickslock`序列化这两个访问。

自旋锁和中断的相互作用带来了潜在的危险。假设`sys_sleep`持有tickslock，它的CPU被定时器中断，clockintr会尝试获取tickslock，看到它被持有，然后等待它被释放。在这种情况下，`tickslock`永远不会释放：只有`sys_sleep`可以释放，但是`sys_sleep`在clockintrurn返回之前不会继续运行。所以CPU会死锁，任何需要这两个锁的代码也会冻结。

为了避免这种情况，如果中断处理程序使用自旋锁，CPU绝不能在启用中断的情况下持有该锁。xv6更为保守：当CPU获得任何锁时，xv6总是禁用该CPU上的中断。中断可能仍然发生在其他CPU上，因此中断的“获取”可以等待线程释放自旋锁；只是不在同一个CPU上。

当CPU没有持有旋转锁时，xv6会重新启用中断；它必须执行一些记账操作来处理嵌套的临界区。`quire`调用`ush_off`(kernel/splock.c：87)，`release`调用`popoff`(kernel/spinlock.c：98)来跟踪当前CPU上锁的嵌套级别。当该计数达到零时，`POP_OFF‘恢复存在于最外层临界区开始处的中断启用状态。intr_off和intr_on函数执行RISC-V指令，分别禁用和启用中断。

在设置`lk->locked`(kernel/splock.c：28)之前，`quire`一定要严格调用`ush_off`。如果两者颠倒，则在启用中断的情况下保持锁定时会有一个短暂的窗口，并且不幸的定时中断会使系统死锁。同样重要的是，只有在释放锁之后才释放`ecall``popoff`(kernel/osplock.c：63)。




### 5.6指令和内存排序。

按照源代码语句出现的顺序来执行程序是很自然的。然而，许多编译器和CPU无序地执行代码以实现更高的性能。如果一条指令需要很多周期才能完成，CPU可能会提前发出该指令，以便它可以与其他指令重叠并避免CPU停顿。例如，CPU可以注意到，在指令A和B的串行序列中，指令A和B彼此不依赖。CPU可以首先启动指令B，因为它的输入在A的输入之前就准备好了，或者为了重叠A和B的执行。编译器可以通过在源代码中针对其前面的语句的指令之前发出针对一条语句的指令来执行类似的重新排序。

编译器和CPU在重新排序时遵循规则，以确保它们不会更改正确编写的串行代码的结果。但是，这些规则确实允许重新排序，从而更改并发代码的结果，并且很容易导致多处理器[2，3]上的不正确行为。CPU的排序规则称为“内存模型”。

例如，在这段FORPUSH代码中，如果编译器或CPU将对应于第4行的存储移动到第6行的`release‘之后的某个位置，那将是一场灾难：

```c
1 l = malloc(sizeof *l);
2 l->data = data;
3 acquire(&listlock);
4 l->next = list;
5 list = l;
6 release(&listlock);
```

如果发生这样的重新排序，则会有一个窗口，在此期间，另一个CPU可以获取锁并观察更新列表，但会看到未初始化的`List->next`。

为了告诉硬件和编译器不要进行这样的重新排序，xv6在`quire`(kernel/splock.c：22)和`release ase`(kernel/splock.c：46)中都使用了__sync_synchronize()。__sync_synchronize()是一个`内存屏障‘：它告诉编译器和CPU不要跨过障碍对加载或存储进行重新排序。

xv6的“获取”和“释放”中的障碍几乎在所有重要的情况下都强制执行顺序，因为xv6在访问共享数据时使用锁。第8章讨论了几个例外情况。

### 5.7睡眠锁。

有时xv6需要长时间保持锁定。例如，文件系统(第7章)在磁盘上读写文件内容时将其锁定，而这些磁盘操作可能需要数十毫秒。如果另一个进程想要获取一个自旋锁，那么长时间持有它将导致浪费，因为获取进程会在旋转过程中浪费很长时间的CPU。自旋锁的另一个缺点是，进程在保留自旋锁的同时不能释放CPU；我们希望这样做，以便其他进程可以在拥有该锁的进程等待磁盘时使用该CPU。

在持有自旋锁时让步是非法的，因为如果第二个线程随后试图“获取”该自旋锁，可能会导致死锁；由于“quiqure`”不会产生CPU，因此第二个线程的旋转可能会阻止第一线程运行和释放锁。在持有锁的同时让步也会违反在持有自旋锁时必须关闭中断的要求。因此，我们想要一种在等待获取时产生CPU，并允许在持有锁时产生(和中断)的锁。

Xv6以`睡眠锁`的形式提供这样的锁。`quire``sleep`(kernel/sleeplock.c：22)在等待时会产生CPU，使用的技术将在第6章介绍。在较高级别上，睡眠锁有一个受Spinlock保护的ockedfield，而`quire`睡眠对`sleep`的调用会原子地产生CPU并释放Spinlock。结果是，其他线程可以在‘quire`休眠等待期间执行。

因为休眠锁使中断处于启用状态，所以它们不能在中断处理程序中使用。因为‘quire`’‘sleep`可能会产生CPU，所以不能在自旋锁临界区内使用休眠锁(尽管可以在休眠锁临界区内使用自旋锁)。

自旋锁最适合于较短的临界区，因为等待它们会浪费CPU时间；休眠锁很适合长时间的操作。



### 5.8真实世界。

尽管对并发原语和并行性进行了多年的研究，但使用锁进行编程仍然具有挑战性。通常最好将锁隐藏在更高级别的构造(如同步队列)中，尽管xv6不能做到这一点。如果您使用锁进行编程，明智的做法是使用试图识别争用条件的工具，因为很容易错过需要锁的不变量。

大多数操作系统支持POSIX线程(Pthread)，这允许用户进程在不同的CPU上同时运行多个线程。Pthread支持用户级锁、障碍等。支持Pthread需要操作系统的支持。例如，如果一个pthread阻塞在系统调用中，则同一进程的另一个pthread应该能够在该CPU上运行。作为另一示例，如果pthread改变其进程的地址空间(例如，映射或取消映射存储器)，则内核必须安排运行相同进程的线程的其他CPU更新它们的硬件页表以反映地址空间中的改变。

可以在没有原子指令的情况下实现锁，但代价很高，而且大多数操作系统都使用原子指令。

如果多个CPU尝试同时获取相同的锁，则锁可能会很昂贵。如果一个CPU在其本地高速缓存中缓存了一个锁，并且另一个CPU必须获取该锁，则更新持有该锁的高速缓存线的原子指令必须将该线从一个CPU的高速缓存移动到另一个CPU的高速缓存，并且可能使该高速缓存线的任何其他副本无效。从另一个CPU的高速缓存中提取高速缓存线的开销可能比从本地高速缓存中提取线的成本高出数量级。

为了避免与锁相关的开销，许多操作系统使用无锁的数据结构和算法。例如，可以实现类似于本章开头的链表，该链表在列表搜索期间不需要锁定，并且可以实现在列表中插入项的一条原子指令。然而，无锁编程比编程锁更复杂；例如，人们必须担心指令和内存的重新排序。使用锁进行编程已经很困难，因此xv6避免了无锁编程的额外复杂性。


### 5.9练习。

1. 注释掉`kalloc`(kernel/kalloc.c：69)中对`quire`和`release ase`的调用。这似乎应该会给调用“kalloc”的内核代码带来问题；您预计会看到什么症状？当您运行xv6时，您看到这些症状了吗？那么在运行用户测试时呢？如果你看不到问题，何乐而不为呢？看看您是否可以通过将虚拟循环插入到`kalloc`的临界区来引发问题。
2. 假设您注释掉了`kfre`中的锁定(在`kalloc`中恢复锁定后)。现在可能会出什么问题呢？缺少无墨水的锁比‘卡洛克锁’有害吗？
3. 如果两个CPU同时调用`kalloc`，其中一个需要等待另一个，这会影响性能。修改`kalloc`.c使其更具并行性，这样不同CPU对`kalloc`的同时调用就可以进行，无需等待。
4. 使用POSIX线程编写并行程序，大多数操作系统都支持POSIX线程。例如，实现并行哈希表，并测量Put/Get的数量是否随着内核数量的增加而扩展。
5. 在xv6中实现Pthread子集。也就是说，实现一个用户级线程库，以便一个用户进程可以有一个以上的线程，并安排这些线程可以在不同的CPU上并行运行。设计一种正确处理线程、阻塞系统调用并更改其共享地址空间的设计。
